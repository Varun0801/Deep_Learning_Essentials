{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>147</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>228</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>91</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>202</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     29   65    0   2       140   417    1        0      157      0      0.8   \n",
       "1     57   48    1   0       122   222    0        0      186      0      0.0   \n",
       "2      9   52    1   2       172   199    1        1      162      0      0.5   \n",
       "3    147   44    0   2       118   242    0        1      149      0      0.3   \n",
       "4    303   57    0   1       130   236    0        0      174      0      0.0   \n",
       "..   ...  ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "248  228   35    1   0       120   198    0        1      130      1      1.6   \n",
       "249   91   48    1   2       124   255    1        1      175      0      0.0   \n",
       "250  138   62    1   1       128   208    1        0      140      0      0.0   \n",
       "251  202   60    1   0       125   258    0        0      141      1      2.8   \n",
       "252   46   52    1   1       120   325    0        1      172      0      0.2   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        2   1     2       1  \n",
       "1        2   0     2       1  \n",
       "2        2   0     3       1  \n",
       "3        1   1     2       1  \n",
       "4        1   1     2       0  \n",
       "..     ...  ..   ...     ...  \n",
       "248      1   0     3       0  \n",
       "249      2   2     2       1  \n",
       "250      2   0     2       1  \n",
       "251      1   1     3       0  \n",
       "252      2   0     2       1  \n",
       "\n",
       "[253 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C://Users//VARUN SAKUNIA//Desktop//Final.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253 entries, 0 to 252\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        253 non-null    int64  \n",
      " 1   age       253 non-null    int64  \n",
      " 2   sex       253 non-null    int64  \n",
      " 3   cp        253 non-null    int64  \n",
      " 4   trestbps  253 non-null    int64  \n",
      " 5   chol      253 non-null    int64  \n",
      " 6   fbs       253 non-null    int64  \n",
      " 7   restecg   253 non-null    int64  \n",
      " 8   thalach   253 non-null    int64  \n",
      " 9   exang     253 non-null    int64  \n",
      " 10  oldpeak   253 non-null    float64\n",
      " 11  slope     253 non-null    int64  \n",
      " 12  ca        253 non-null    int64  \n",
      " 13  thal      253 non-null    int64  \n",
      " 14  target    253 non-null    int64  \n",
      "dtypes: float64(1), int64(14)\n",
      "memory usage: 29.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['ID','target'],axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 13)\n",
      "(253,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "from tensorflow import keras  \n",
    "\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\VARUN SAKUNIA\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))   \n",
    "#model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\VARUN SAKUNIA\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "optimizer = RMSprop(0.001)  \n",
    "model.compile(loss='binary_crossentropy', optimizer= 'adam' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,121\n",
      "Trainable params: 1,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161 samples, validate on 41 samples\n",
      "Epoch 1/70\n",
      "161/161 [==============================] - 0s 1ms/sample - loss: 2.4978 - acc: 0.3913 - val_loss: 1.4025 - val_acc: 0.4146\n",
      "Epoch 2/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 1.2748 - acc: 0.4472 - val_loss: 0.6021 - val_acc: 0.6829\n",
      "Epoch 3/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.9764 - acc: 0.5280 - val_loss: 0.6716 - val_acc: 0.5610\n",
      "Epoch 4/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.8620 - acc: 0.5963 - val_loss: 0.6488 - val_acc: 0.6341\n",
      "Epoch 5/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.8958 - acc: 0.5590 - val_loss: 0.8560 - val_acc: 0.5854\n",
      "Epoch 6/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.9789 - acc: 0.5342 - val_loss: 0.5671 - val_acc: 0.6829\n",
      "Epoch 7/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.8080 - acc: 0.5776 - val_loss: 0.5582 - val_acc: 0.6585\n",
      "Epoch 8/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.7106 - acc: 0.6398 - val_loss: 0.6452 - val_acc: 0.6098\n",
      "Epoch 9/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.8213 - acc: 0.6273 - val_loss: 1.1332 - val_acc: 0.4634\n",
      "Epoch 10/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.8374 - acc: 0.5776 - val_loss: 0.5044 - val_acc: 0.7561\n",
      "Epoch 11/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.9979 - acc: 0.4969 - val_loss: 0.6368 - val_acc: 0.6585\n",
      "Epoch 12/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.8279 - acc: 0.6087 - val_loss: 0.4337 - val_acc: 0.7073\n",
      "Epoch 13/70\n",
      "161/161 [==============================] - 0s 249us/sample - loss: 0.6560 - acc: 0.6398 - val_loss: 0.4040 - val_acc: 0.8780\n",
      "Epoch 14/70\n",
      "161/161 [==============================] - 0s 249us/sample - loss: 0.6668 - acc: 0.5963 - val_loss: 0.3852 - val_acc: 0.8293\n",
      "Epoch 15/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.6458 - acc: 0.6770 - val_loss: 0.4096 - val_acc: 0.8049\n",
      "Epoch 16/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.6011 - acc: 0.6522 - val_loss: 0.4376 - val_acc: 0.7561\n",
      "Epoch 17/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5872 - acc: 0.6646 - val_loss: 0.4186 - val_acc: 0.9024\n",
      "Epoch 18/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.5327 - acc: 0.7329 - val_loss: 0.4218 - val_acc: 0.9024\n",
      "Epoch 19/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.5266 - acc: 0.7702 - val_loss: 0.3969 - val_acc: 0.8537\n",
      "Epoch 20/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5358 - acc: 0.7516 - val_loss: 0.4118 - val_acc: 0.8293\n",
      "Epoch 21/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5245 - acc: 0.7205 - val_loss: 0.4199 - val_acc: 0.8049\n",
      "Epoch 22/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5557 - acc: 0.6708 - val_loss: 0.4551 - val_acc: 0.7561\n",
      "Epoch 23/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.6258 - acc: 0.6894 - val_loss: 0.3970 - val_acc: 0.8780\n",
      "Epoch 24/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5151 - acc: 0.7578 - val_loss: 0.3920 - val_acc: 0.8537\n",
      "Epoch 25/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5413 - acc: 0.7143 - val_loss: 0.4384 - val_acc: 0.8049\n",
      "Epoch 26/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.5842 - acc: 0.6584 - val_loss: 0.4099 - val_acc: 0.8293\n",
      "Epoch 27/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.5090 - acc: 0.7640 - val_loss: 0.4114 - val_acc: 0.7805\n",
      "Epoch 28/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5252 - acc: 0.7453 - val_loss: 0.3907 - val_acc: 0.8293\n",
      "Epoch 29/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5348 - acc: 0.7516 - val_loss: 0.4220 - val_acc: 0.7317\n",
      "Epoch 30/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4980 - acc: 0.7516 - val_loss: 0.4154 - val_acc: 0.7805\n",
      "Epoch 31/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4941 - acc: 0.7764 - val_loss: 0.6554 - val_acc: 0.5610\n",
      "Epoch 32/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.6297 - acc: 0.6211 - val_loss: 0.3973 - val_acc: 0.8049\n",
      "Epoch 33/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5198 - acc: 0.7578 - val_loss: 0.3845 - val_acc: 0.8780\n",
      "Epoch 34/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4706 - acc: 0.7702 - val_loss: 0.3816 - val_acc: 0.7805\n",
      "Epoch 35/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5686 - acc: 0.6894 - val_loss: 0.4468 - val_acc: 0.8049\n",
      "Epoch 36/70\n",
      "161/161 [==============================] - 0s 149us/sample - loss: 0.6266 - acc: 0.6894 - val_loss: 0.5908 - val_acc: 0.6585\n",
      "Epoch 37/70\n",
      "161/161 [==============================] - 0s 193us/sample - loss: 0.5724 - acc: 0.7143 - val_loss: 0.3355 - val_acc: 0.9024\n",
      "Epoch 38/70\n",
      "161/161 [==============================] - 0s 169us/sample - loss: 0.4909 - acc: 0.7640 - val_loss: 0.3502 - val_acc: 0.8780\n",
      "Epoch 39/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4556 - acc: 0.7950 - val_loss: 0.3759 - val_acc: 0.8293\n",
      "Epoch 40/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4796 - acc: 0.7826 - val_loss: 0.4562 - val_acc: 0.7805\n",
      "Epoch 41/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5491 - acc: 0.7143 - val_loss: 0.4238 - val_acc: 0.7805\n",
      "Epoch 42/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4743 - acc: 0.7950 - val_loss: 0.3885 - val_acc: 0.8293\n",
      "Epoch 43/70\n",
      "161/161 [==============================] - 0s 149us/sample - loss: 0.4910 - acc: 0.7329 - val_loss: 0.4478 - val_acc: 0.7805\n",
      "Epoch 44/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5090 - acc: 0.7578 - val_loss: 0.4307 - val_acc: 0.8049\n",
      "Epoch 45/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5111 - acc: 0.6957 - val_loss: 0.3857 - val_acc: 0.8293\n",
      "Epoch 46/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.6010 - acc: 0.6832 - val_loss: 0.4942 - val_acc: 0.7805\n",
      "Epoch 47/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.7554 - acc: 0.6522 - val_loss: 0.5577 - val_acc: 0.7561\n",
      "Epoch 48/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.5154 - acc: 0.7391 - val_loss: 0.5078 - val_acc: 0.7805\n",
      "Epoch 49/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.4687 - acc: 0.7764 - val_loss: 0.3281 - val_acc: 0.8537\n",
      "Epoch 50/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4302 - acc: 0.8137 - val_loss: 0.3364 - val_acc: 0.8780\n",
      "Epoch 51/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4693 - acc: 0.7640 - val_loss: 0.3731 - val_acc: 0.8293\n",
      "Epoch 52/70\n",
      "161/161 [==============================] - 0s 249us/sample - loss: 0.5332 - acc: 0.7143 - val_loss: 0.3575 - val_acc: 0.8049\n",
      "Epoch 53/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4668 - acc: 0.7826 - val_loss: 0.4736 - val_acc: 0.7561\n",
      "Epoch 54/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5742 - acc: 0.7019 - val_loss: 0.4096 - val_acc: 0.8049\n",
      "Epoch 55/70\n",
      "161/161 [==============================] - 0s 248us/sample - loss: 0.4480 - acc: 0.8012 - val_loss: 0.4782 - val_acc: 0.7805\n",
      "Epoch 56/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5693 - acc: 0.7019 - val_loss: 0.3182 - val_acc: 0.8293\n",
      "Epoch 57/70\n",
      "161/161 [==============================] - 0s 198us/sample - loss: 0.4903 - acc: 0.7640 - val_loss: 0.3399 - val_acc: 0.9268\n",
      "Epoch 58/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4435 - acc: 0.7950 - val_loss: 0.3838 - val_acc: 0.8293\n",
      "Epoch 59/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4754 - acc: 0.7640 - val_loss: 0.3389 - val_acc: 0.9024\n",
      "Epoch 60/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4209 - acc: 0.8199 - val_loss: 0.3178 - val_acc: 0.9024\n",
      "Epoch 61/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4154 - acc: 0.8012 - val_loss: 0.3532 - val_acc: 0.8537\n",
      "Epoch 62/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4359 - acc: 0.8199 - val_loss: 0.4359 - val_acc: 0.8049\n",
      "Epoch 63/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5256 - acc: 0.7081 - val_loss: 0.4098 - val_acc: 0.8049\n",
      "Epoch 64/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5096 - acc: 0.7578 - val_loss: 0.3672 - val_acc: 0.8293\n",
      "Epoch 65/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.5151 - acc: 0.7205 - val_loss: 0.3986 - val_acc: 0.8293\n",
      "Epoch 66/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4487 - acc: 0.7950 - val_loss: 0.3898 - val_acc: 0.8049\n",
      "Epoch 67/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4087 - acc: 0.8199 - val_loss: 0.2956 - val_acc: 0.9024\n",
      "Epoch 68/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4555 - acc: 0.7640 - val_loss: 0.3170 - val_acc: 0.9024\n",
      "Epoch 69/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4210 - acc: 0.8012 - val_loss: 0.3695 - val_acc: 0.7805\n",
      "Epoch 70/70\n",
      "161/161 [==============================] - 0s 199us/sample - loss: 0.4144 - acc: 0.8261 - val_loss: 0.3450 - val_acc: 0.8780\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=70, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 314us/sample - loss: 0.4703 - acc: 0.8235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4702713828460843, 0.8235294]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
